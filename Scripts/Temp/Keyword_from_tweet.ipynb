{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keyword_from_tweet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"0p_r-sxREQ6-","colab_type":"code","outputId":"d000a4c3-f6b3-4c51-dc72-857898e489c0","executionInfo":{"status":"ok","timestamp":1555826409365,"user_tz":-330,"elapsed":10521,"user":{"displayName":"Akash Nath","photoUrl":"","userId":"02782343292061640515"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["!pip install jieba\n","!git clone https://github.com/Cryptum169/Rake_For_Chinese.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (0.39)\n","Cloning into 'Rake_For_Chinese'...\n","remote: Enumerating objects: 77, done.\u001b[K\n","remote: Total 77 (delta 0), reused 0 (delta 0), pack-reused 77\u001b[K\n","Unpacking objects: 100% (77/77), done.\n"],"name":"stdout"}]},{"metadata":{"id":"MEP36K7kwkv3","colab_type":"code","outputId":"e3e88592-15d8-4721-90f6-aa13ba8c2c05","executionInfo":{"status":"ok","timestamp":1556081908641,"user_tz":-330,"elapsed":47329,"user":{"displayName":"Akash Nath","photoUrl":"","userId":"02782343292061640515"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"hmahq4x4evrK","colab_type":"code","colab":{}},"cell_type":"code","source":["import jieba\n","import jieba.posseg as pseg\n","import operator\n","import json\n","from collections import Counter\n","\n","\n","# Data structure for holding data\n","class Word():\n","    def __init__(self, char, freq = 0, deg = 0):\n","        self.freq = freq\n","        self.deg = deg\n","        self.char = char\n","\n","    def returnScore(self):\n","        return self.deg/self.freq\n","\n","    def updateOccur(self, phraseLength):\n","        self.freq += 1\n","        self.deg += phraseLength\n","\n","    def getChar(self):\n","        return self.char\n","\n","    def updateFreq(self):\n","        self.freq += 1\n","\n","    def getFreq(self):\n","        return self.freq\n","\n","# Check if contains num\n","def notNumStr(instr):\n","    for item in instr:\n","        if '\\u0041' <= item <= '\\u005a' or ('\\u0061' <= item <='\\u007a') or item.isdigit():\n","            return False\n","    return True\n","\n","# Read Target Case if Json\n","def readSingleTestCases(testFile):\n","    with open(testFile) as json_data:\n","        try:\n","            testData = json.load(json_data)\n","        except:\n","            # This try block deals with incorrect json format that has ' instead of \"\n","            data = json_data.read().replace(\"'\",'\"')\n","            try:\n","                testData = json.loads(data)\n","                # This try block deals with empty transcript file\n","            except:\n","                return \"\"\n","    returnString = \"\"\n","    for item in testData:\n","        try:\n","            returnString += item['text']\n","        except:\n","            returnString += item['statement']\n","    return returnString\n","\n","def run(rawText):\n","    # Construct Stopword Lib\n","    swLibList = [line.rstrip('\\n') for line in open(\"Rake_For_Chinese/data/stoplist/中文停用词表(1208个).txt\",'r')]\n","    # Construct Phrase Deliminator Lib\n","    conjLibList = [line.rstrip('\\n') for line in open(\"Rake_For_Chinese/data/stoplist/中文分隔词词库.txt\",'r')]\n","\n","    # Cut Text\n","    rawtextList = pseg.cut(rawText)\n","\n","    # Construct List of Phrases and Preliminary textList\n","    textList = []\n","    listofSingleWord = dict()\n","    lastWord = ''\n","    poSPrty = ['m','x','uj','ul','mq','u','v','f']\n","    meaningfulCount = 0\n","    checklist = []\n","    for eachWord, flag in rawtextList:\n","        checklist.append([eachWord,flag])\n","        if eachWord in conjLibList or not notNumStr(eachWord) or eachWord in swLibList or flag in poSPrty or eachWord == '\\n':\n","            if lastWord != '|':\n","                textList.append(\"|\")\n","                lastWord = \"|\"\n","        elif eachWord not in swLibList and eachWord != '\\n':\n","            textList.append(eachWord)\n","            meaningfulCount += 1\n","            if eachWord not in listofSingleWord:\n","                listofSingleWord[eachWord] = Word(eachWord)\n","            lastWord = ''\n","\n","    # Construct List of list that has phrases as wrds\n","    newList = []\n","    tempList = []\n","    for everyWord in textList:\n","        if everyWord != '|':\n","            tempList.append(everyWord)\n","        else:\n","            newList.append(tempList)\n","            tempList = []\n","\n","    tempStr = ''\n","    for everyWord in textList:\n","        if everyWord != '|':\n","            tempStr += everyWord + '|'\n","        else:\n","            if tempStr[:-1] not in listofSingleWord:\n","                listofSingleWord[tempStr[:-1]] = Word(tempStr[:-1])\n","                tempStr = ''\n","\n","    # Update the entire List\n","    for everyPhrase in newList:\n","        res = ''\n","        for everyWord in everyPhrase:\n","            listofSingleWord[everyWord].updateOccur(len(everyPhrase))\n","            res += everyWord + '|'\n","        phraseKey = res[:-1]\n","        if phraseKey not in listofSingleWord:\n","            listofSingleWord[phraseKey] = Word(phraseKey)\n","        else:\n","            listofSingleWord[phraseKey].updateFreq()\n","\n","    # Get score for entire Set\n","    outputList = dict()\n","    for everyPhrase in newList:\n","\n","        if len(everyPhrase) > 5:\n","            continue\n","        score = 0\n","        phraseString = ''\n","        outStr = ''\n","        for everyWord in everyPhrase:\n","            score += listofSingleWord[everyWord].returnScore()\n","            phraseString += everyWord + '|'\n","            outStr += everyWord\n","        phraseKey = phraseString[:-1]\n","        freq = listofSingleWord[phraseKey].getFreq()\n","        if freq / meaningfulCount < 0.01 and freq < 3 :\n","            continue\n","        outputList[outStr] = score\n","\n","    sorted_list = sorted(outputList.items(), key = operator.itemgetter(1), reverse = True)\n","    return sorted_list[:10]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UVXvxOP4yizv","colab_type":"code","outputId":"d9dda429-8c6b-4c67-c51e-e44e59c6040b","executionInfo":{"status":"ok","timestamp":1555831651164,"user_tz":-330,"elapsed":1054,"user":{"displayName":"Akash Nath","photoUrl":"","userId":"02782343292061640515"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/gdrive/My Drive/Dataset/User_profile_id_name.txt\",sep = \"\\t\",header= None)\n","df.columns = columns = [\"User_id\",\"name\"]\n","df['User_id'] = df['User_id'].astype('int64')\n","df=df.sort_values(['User_id']).reset_index(drop=True)\n","df['tweet'] = \"\"\n","df['tweet'][df['name'].isnull()] = 'None'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  \n"],"name":"stderr"}]},{"metadata":{"id":"p2JQLRlEyeaq","colab_type":"code","colab":{}},"cell_type":"code","source":["flag = 0\n","u_keywords=\"\"\n","\n","with open('/content/gdrive/My Drive/Dataset/User_tweets.txt','r',encoding=\"utf-8\") as f:\n","    for line in f:\n","        if flag == 0:\n","            u_index,u_id,u_name = line.split('\\t')\n","            u_id = int(u_id)\n","            u_str = \"\"\n","            flag=1\n","            continue\n","        if line == \"---------------------------------------------------------------------\\n\":\n","            flag=0\n","            if u_str == 'None' or u_str == \"\":\n","              u_keywords = 'None'\n","            if u_keywords != 'None':\n","              try:\n","                keywords_array = []\n","                for i,j in run(u_str):\n","                  keywords_array.append(i)\n","                u_keywords=';'.join(keywords_array)\n","              except Exception as e:\n","                print(u_index,\":\",u_str,\":\",e)\n","                u_keywords = 'None'\n","            df['tweet'][df['User_id'] == u_id] = u_keywords\n","            u_keywords=\"\"\n","        u_str +=line.strip('\\n') #TODO: remove HTML tags <a href...>"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yiyoD9U8tvom","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","User_tweets = pd.read_csv(\"/content/gdrive/My Drive/Dataset/tweet_keyword.txt\",sep = \"\\t\",header= None)\n","User_tweets.columns = [\"drop\",\"User_id\",\"name\",\"tweet\"]\n","User_tweets['User_id'] = User_tweets['User_id'].astype('int64')\n","del User_tweets['drop']\n","User_tweets['tweet'][User_tweets['tweet'].isna()] = 'None'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l6qcJalXwTUM","colab_type":"code","colab":{}},"cell_type":"code","source":["ls = []\n","\n","def add_to_list(tweet_str):\n","    #ls.append([i.strip() for i  in tweet_str.split(';')])\n","    ls.append(tweet_str.split(';'))\n","    return tweet_str\n","\n","User_tweets['tweet'].apply(add_to_list)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JMG_rwVV7owL","colab_type":"code","outputId":"854c7573-0709-4007-981f-26f470e30efb","executionInfo":{"status":"ok","timestamp":1555517156082,"user_tz":-330,"elapsed":1540,"user":{"displayName":"Akash Nath","photoUrl":"","userId":"02782343292061640515"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["User_checkin=pd.merge(UserProfile,df,on=\"User_id\")\n","User_checkin = User_checkin.sort_values(['User_id']).reset_index(drop=True)\n","\n","for index,row in User_checkin[0:10].iterrows():\n","  temp = row.tweet.split(';')  + [row.User_id,row.Place]\n","  print(temp)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['三亚国际电音节', '三亚国际音乐节', '广大乐迷', '儿童手表', '目前', '三亚', '儿童', '雷音', '安全', '视频', 35277, 'Dongcheng District, Beijing']\n","['组队战胜鬼王', '式神', '人品好', '平安京', '现世活动', '小小黑', '阴阳师手游', '阴阳师', '红包', '鬼王', 48827, 'Shijingshan District, Beijing']\n","['别样意大利餐', '肉沫豆腐', '关西经典', '亲子盖饭', '特别值得一提的是', '阿当厉害', '红烧鸡腿', '北京主食', '馒头', '寿喜', 101707, 'nan']\n","['竞园图片产业基地', '投资', '小', '时', '已', '稳定', '局', '德国', '已经', '公司', 103500, 'Chaoyang District, Beijing']\n","['今天', '明明', '爱情', '人类', '机派', '不幸', '事', '孩子', '味道', '人', 103984, 'Chaoyang District, Beijing']\n","['None', 104127, 'Chaoyang District, Beijing']\n","['None', 104174, 'Chaoyang District, Beijing']\n","['暖暖环游世界', '完美评分', '小米手机', '手机', '最', '小米', '二维码', '试试', '老虎', '刚刚', 104899, 'Beijing Haidian District']\n","['亚历山大心痛', '反季节旅行', '新西兰疯狂', '传花', '没良心', '倒霉', '朵花', '身', '杜蕾斯', '先是', 120430, 'nan']\n","['None', 397625, 'Chaoyang District, Beijing']\n"],"name":"stdout"}]},{"metadata":{"id":"vKXbYg_8hy1w","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}