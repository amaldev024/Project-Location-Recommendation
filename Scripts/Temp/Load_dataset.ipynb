{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year</th>\n",
       "      <th>Horoscope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381078220</td>\n",
       "      <td>Shanghai Putuo District</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1723807154</td>\n",
       "      <td>Xuhui District, Shanghai</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500165530</td>\n",
       "      <td>Shanghai Pudong New Area</td>\n",
       "      <td>female</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1246687181</td>\n",
       "      <td>Shanghai Pudong New Area</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aquarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1871921945</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>female</td>\n",
       "      <td>1982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_id                     Place  Gender  Year Horoscope\n",
       "0  1381078220   Shanghai Putuo District  female   NaN       NaN\n",
       "1  1723807154  Xuhui District, Shanghai    male   NaN       Leo\n",
       "2  1500165530  Shanghai Pudong New Area  female  1989       NaN\n",
       "3  1246687181  Shanghai Pudong New Area  female   NaN  Aquarius\n",
       "4  1871921945                  Shanghai  female  1982       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "UserProfile=pd.read_csv('weiboUserProfile_csv.txt',header=None,sep=':')\n",
    "UserProfile.columns=['User_id','Place','Gender','Year','Horoscope']\n",
    "UserProfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_id      507471\n",
      "Place        319704\n",
      "Gender       319704\n",
      "Year         185577\n",
      "Horoscope     81552\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "UserInfo=UserProfile.count(axis=0, level=None, numeric_only=False)\n",
    "print(UserInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_id</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Place</th>\n",
       "      <th>Comment_1</th>\n",
       "      <th>Comment_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j:1A4F169FAF4A8E</td>\n",
       "      <td>31.240782</td>\n",
       "      <td>121.548460</td>\n",
       "      <td>shanghai</td>\n",
       "      <td>Leisure / Entertainment / Culture</td>\n",
       "      <td>Cinema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j:229AF0E87884E5D7E9B827A442E07E4B</td>\n",
       "      <td>22.297639</td>\n",
       "      <td>114.178022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j:15805000759218470558</td>\n",
       "      <td>22.297428</td>\n",
       "      <td>114.172607</td>\n",
       "      <td>overseas</td>\n",
       "      <td>Public institution/office/residential</td>\n",
       "      <td>Apartment / Community / Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j:2551510332343224024</td>\n",
       "      <td>-33.815418</td>\n",
       "      <td>151.003494</td>\n",
       "      <td>overseas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j:494CC18DC9A57D3B1770D5560DC6681F</td>\n",
       "      <td>23.900358</td>\n",
       "      <td>120.587242</td>\n",
       "      <td>changhua</td>\n",
       "      <td>Public institution/office/residential</td>\n",
       "      <td>Office/office</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Location_id   Latitude   Longitude     Place  \\\n",
       "0                    j:1A4F169FAF4A8E  31.240782  121.548460  shanghai   \n",
       "1  j:229AF0E87884E5D7E9B827A442E07E4B  22.297639  114.178022       NaN   \n",
       "2              j:15805000759218470558  22.297428  114.172607  overseas   \n",
       "3               j:2551510332343224024 -33.815418  151.003494  overseas   \n",
       "4  j:494CC18DC9A57D3B1770D5560DC6681F  23.900358  120.587242  changhua   \n",
       "\n",
       "                               Comment_1                     Comment_2  \n",
       "0      Leisure / Entertainment / Culture                        Cinema  \n",
       "1                                    NaN                           NaN  \n",
       "2  Public institution/office/residential  Apartment / Community / Lane  \n",
       "3                                    NaN                           NaN  \n",
       "4  Public institution/office/residential                 Office/office  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LocationProfile=pd.read_csv('poiInfo_jiepang.txt',header=None,sep=',')\n",
    "LocationProfile.columns=['Location_id','Latitude','Longitude','Place','Comment_1','Comment_2']\n",
    "LocationProfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location_id    1016370\n",
      "Latitude        963874\n",
      "Longitude       963874\n",
      "Place           981502\n",
      "Comment_1       490784\n",
      "Comment_2       490784\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LocationInfo=LocationProfile.count(axis=0, level=None, numeric_only=False)\n",
    "print(LocationInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CheckinInfo=pd.read_csv('checkin_bj_uniq.txt',header=None,sep='\\t')\n",
    "CheckinInfo.columns=['User_id','Time','latitude','longititude','Item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "a1=CheckinInfo.groupby( [ \"User_id\", \"Item_id\"] ).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "#Creating Item_label\n",
    "b_item=sorted(a1[\"Item_id\"].unique())\n",
    "Item_label=pd.DataFrame(b_item)\n",
    "Item_label.columns=[\"Item_id\"]\n",
    "\n",
    "person_c = CategoricalDtype(sorted(a1.User_id.unique()), ordered=True)\n",
    "thing_c = CategoricalDtype(sorted(a1.Item_id.unique()), ordered=True)\n",
    "\n",
    "row = a1.User_id.astype(person_c).cat.codes\n",
    "col = a1.Item_id.astype(thing_c).cat.codes\n",
    "sparse_checkin = csr_matrix((a1['count'], (row, col)),shape=(person_c.categories.size, thing_c.categories.size))\n",
    "\n",
    "#Converting sparse-matrix to dataframe \n",
    "#dfs = pd.SparseDataFrame(sparse_checkin, index=person_c.categories, columns=thing_c.categories,default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of check-ins: 1992299\n",
      "Users * Items: (55650, 213673)\n",
      "Sparsity 0.9998324518253869\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# zero to zero mapping\n",
    "# X.data[:] = np.sqrt(X.data)<-- non-zero values\n",
    "# X.A<-- overall array\n",
    "\n",
    "#Use sparse[:,:].toarray() to print elemnts\n",
    "\n",
    "print(\"No of check-ins:\",np.count_nonzero(sparse_checkin.data))\n",
    "print(\"Users * Items:\",sparse_checkin.shape)\n",
    "a,b=sparse_checkin.shape\n",
    "density=np.count_nonzero(sparse_checkin.data)/(a*b)\n",
    "sparsity=1-density\n",
    "print(\"Sparsity\",sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating binary_visit matrix\n",
    "binary_checkin=sparse_checkin>0\n",
    "binary_checkin=1*binary_checkin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already generated..dont execute again.\n",
    "#to write the pyTable\n",
    "#creating confidence matrix\n",
    "import tables as tb\n",
    "import tqdm\n",
    "with tb.open_file('confid_matrix.h5', 'w') as f:\n",
    "    filters = tb.Filters(complevel=5, complib='blosc')\n",
    "    out = f.create_carray(f.root, 'data', tb.Float32Atom(), shape=sparse_checkin.shape, filters=filters)\n",
    "    alpha=3\n",
    "    with tqdm.tqdm(total=55650) as progress:\n",
    "        for i in range(55650):\n",
    "            out[i,]=(alpha*sparse_checkin[i,].toarray()) + 1\n",
    "            progress.update(1)\n",
    "    f.close()\n",
    "#to read the pyTable\n",
    "# with tb.open_file('confid_matrix.h5', 'r') as f:\n",
    "#     a = f.root.data\n",
    "#     for i in range(100):\n",
    "#         row = a[i,:] #only one row gets loaded into memory\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model_class=AlternatingLeastSquares\n",
    "params = {'factors': 16, 'dtype': np.float32}\n",
    "model=model_class(**params)\n",
    "model.approximate_similar_items = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import bm25_weight\n",
    "sparse_checkin_2 = bm25_weight(sparse_checkin, K1=100, B=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model :als\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:10<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model in 10.75s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"training model :als\")\n",
    "start = time.time()\n",
    "model.fit(sparse_checkin_2.T.tocsr())\n",
    "print(\"trained model in %0.2fs\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 55650/55650 [04:18<00:00, 215.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated recommendations in 258.45s\n"
     ]
    }
   ],
   "source": [
    "user=list(sorted(a1.User_id.unique()))\n",
    "item=list(sorted(a1.Item_id.unique()))\n",
    "\n",
    "import tqdm\n",
    "import codecs\n",
    "\n",
    "start = time.time()\n",
    "output_filename = 'recommend_implicit.txt'\n",
    "user_item = sparse_checkin_2.tocsr()\n",
    "\n",
    "with tqdm.tqdm(total=len(user)) as progress:\n",
    "    with open(output_filename, \"w\") as o:\n",
    "        for u_id in range(len(user)):\n",
    "            for i_id, score in model.recommend(u_id, user_item):\n",
    "                o.write(\"%s\\t%s\\t%s\\n\" %(user[u_id], item[i_id], score))\n",
    "            progress.update(1)           \n",
    "print(\"generated recommendations in %0.2fs\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=CheckinInfo.set_index(\"User_id\",drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:  Evaluation of recommender\n",
    "#https://stats.stackexchange.com/questions/226825/what-metric-should-i-use-for-assessing-implicit-matrix-factorization-recommender\n",
    "#https://github.com/statisticianinstilettos/recmetrics\n",
    "    \n",
    "#TODO:  Metadata Embeddings for User and Item Cold-start Recommendations\n",
    "#https://towardsdatascience.com/creating-a-hybrid-content-collaborative-movie-recommender-using-deep-learning-cc8b431618af\n",
    "#https://towardsdatascience.com/how-to-build-from-scratch-a-content-based-movie-recommender-with-natural-language-processing-25ad400eb243\n",
    "#https://stackoverflow.com/questions/33757974/how-to-add-user-and-item-metadata-in-recommendation-engine-and-which-python-open\n",
    "#https://github.com/jalajthanaki/Movie_recommendation_engine\n",
    "\n",
    "#TODO:matchbox and SVD feature box\n",
    "#https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/score-matchbox-recommender\n",
    "#https://github.com/Azure-Readiness/hol-azure-machine-learning/blob/master/008-lab-recommendation-system.md\n",
    "#https://github.com/beechung/Latent-Factor-Models\n",
    "#https://github.com/Coder-Yu/RecQ\n",
    "\n",
    "\n",
    "#recommender\n",
    "#https://www.coursera.org/specializations/recommender-systems\n",
    "\n",
    "#Matrix Factorization\n",
    "#https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536\n",
    "#https://lazyprogrammer.me/tutorial-on-collaborative-filtering-and-matrix-factorization-in-python/\n",
    "#http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "\n",
    "# TODO NOW:\n",
    "# https://github.com/lyst/lightfm\n",
    "    # https://github.com/jalajthanaki/Movie_recommendation_engine\n",
    "#https://github.com/NicolasHug/Surprise\n",
    "#https://github.com/DefuLian/recsys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/8e/5485ac5a8616abe1c673d1e033e2f232b4319ab95424b42499fabff2257f/lightfm-1.15.tar.gz\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightfm) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightfm) (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightfm) (2.19.1)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightfm) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightfm) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightfm) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightfm) (2018.8.24)\n",
      "Building wheels for collected packages: lightfm\n",
      "  Building wheel for lightfm (setup.py): started\n",
      "  Building wheel for lightfm (setup.py): finished with status 'error'\n",
      "  Complete output from command C:\\Users\\admin\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-406033zc\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\admin\\AppData\\Local\\Temp\\pip-wheel-jcz6xp4i --python-tag cp37:\n",
      "  Compiling without OpenMP support.\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\cross_validation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\data.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\evaluation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\lightfm.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\_lightfm_fast.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  creating build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\movielens.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\stackexchange.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\_common.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\_lightfm_fast_no_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\_lightfm_fast_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  running build_ext\n",
      "  building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for lightfm\n",
      "Failed to build lightfm\n",
      "Installing collected packages: lightfm\n",
      "  Running setup.py install for lightfm: started\n",
      "    Running setup.py install for lightfm: finished with status 'error'\n",
      "    Complete output from command C:\\Users\\admin\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-406033zc\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\admin\\AppData\\Local\\Temp\\pip-record-5fx8lfmt\\install-record.txt --single-version-externally-managed --compile:\n",
      "    Compiling without OpenMP support.\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.7\n",
      "    creating build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\cross_validation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\data.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\evaluation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\lightfm.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\_lightfm_fast.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    creating build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "    copying lightfm\\datasets\\movielens.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "    copying lightfm\\datasets\\stackexchange.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "    copying lightfm\\datasets\\_common.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "    copying lightfm\\datasets\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "    copying lightfm\\_lightfm_fast_no_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    copying lightfm\\_lightfm_fast_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "    running build_ext\n",
      "    building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for lightfm\n",
      "Command \"C:\\Users\\admin\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-406033zc\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\admin\\AppData\\Local\\Temp\\pip-record-5fx8lfmt\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\admin\\AppData\\Local\\Temp\\pip-install-406033zc\\lightfm\\\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/6a/4b2fcefd2ea0868810e92d519dacac1ddc64a2e53ba9e3422c3b62b378a6/setuptools-40.8.0-py2.py3-none-any.whl (575kB)\n",
      "Installing collected packages: setuptools\n",
      "  Found existing installation: setuptools 40.2.0\n",
      "    Uninstalling setuptools-40.2.0:\n",
      "      Successfully uninstalled setuptools-40.2.0\n",
      "Successfully installed setuptools-40.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=list(sorted(a1.User_id.unique()))\n",
    "item=list(sorted(a1.Item_id.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35277"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
